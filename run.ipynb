{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12583497-c220-46ab-bc6a-b87cf465b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from utils.Unet2 import Unet2\n",
    "from utils.vgg16 import VGG16\n",
    "from utils.visualizer_slider import visualizer_slider\n",
    "from utils.segmentation_utils import *\n",
    "from utils.utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85281a41-7ef2-4606-bd03-c0b9882c0cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Loading segmentation model (UNET)\n",
    "model_seg = Unet2(input_nc = 3, output_nc= 1, ngf = 32, bilinear=True)\n",
    "state_dict = torch.load('params/segmentation_net.pth', map_location=str(device)) #\n",
    "model_seg.load_state_dict(state_dict)\n",
    "\n",
    "# Loading classification model (VGG)\n",
    "model_class = VGG16()\n",
    "state_dict = torch.load('params/classifier_net_0.8854F.pth', map_location=str(device)) #\n",
    "model_class.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da3cf9f-6780-4168-a163-ab522e70fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = 'ds/Evaluation'\n",
    "subdir = [join(ds_path, f) for f in os.listdir(ds_path) if os.path.isdir(join(ds_path, f))]\n",
    "\n",
    "file_list = []\n",
    "for f in subdir:\n",
    "    file_list += list_items(f, \".bmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3df18fb2-21a1-4dcf-9c97-8a6608f426e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image name: A01_04.bmp,  TP: 11, FP: 0, FN: 4\n",
      "image name: A01_06.bmp,  TP: 4, FP: 0, FN: 0\n",
      "image name: A01_09.bmp,  TP: 8, FP: 1, FN: 4\n",
      "image name: A03_01.bmp,  TP: 9, FP: 1, FN: 1\n",
      "image name: A03_04.bmp,  TP: 11, FP: 0, FN: 3\n",
      "image name: A03_00.bmp,  TP: 17, FP: 0, FN: 2\n",
      "image name: A00_08.bmp,  TP: 2, FP: 1, FN: 1\n",
      "image name: A00_00.bmp,  TP: 6, FP: 0, FN: 0\n",
      "image name: A02_00.bmp,  TP: 4, FP: 2, FN: 0\n",
      "image name: A02_01.bmp,  TP: 2, FP: 2, FN: 0\n",
      "image name: A02_03.bmp,  TP: 1, FP: 2, FN: 0\n",
      "image name: A02_07.bmp,  TP: 2, FP: 0, FN: 2\n",
      "image name: A04_03.bmp,  TP: 7, FP: 2, FN: 7\n",
      "image name: A04_09.bmp,  TP: 4, FP: 0, FN: 1\n",
      "image name: A04_07.bmp,  TP: 5, FP: 0, FN: 0\n",
      "image name: H03_00.bmp,  TP: 17, FP: 1, FN: 2\n",
      "image name: H03_01.bmp,  TP: 9, FP: 1, FN: 1\n",
      "image name: H03_04.bmp,  TP: 12, FP: 2, FN: 1\n",
      "image name: H04_03.bmp,  TP: 9, FP: 2, FN: 0\n",
      "image name: H04_07.bmp,  TP: 5, FP: 3, FN: 0\n",
      "image name: H04_09.bmp,  TP: 4, FP: 0, FN: 0\n",
      "image name: H02_01.bmp,  TP: 2, FP: 1, FN: 0\n",
      "image name: H02_00.bmp,  TP: 2, FP: 2, FN: 2\n",
      "image name: H02_07.bmp,  TP: 3, FP: 2, FN: 1\n",
      "image name: H02_03.bmp,  TP: 1, FP: 0, FN: 0\n",
      "image name: H01_06.bmp,  TP: 4, FP: 2, FN: 0\n",
      "image name: H01_04.bmp,  TP: 10, FP: 1, FN: 3\n",
      "image name: H01_09.bmp,  TP: 9, FP: 0, FN: 1\n",
      "image name: H00_00.bmp,  TP: 6, FP: 1, FN: 0\n",
      "image name: H00_08.bmp,  TP: 2, FP: 0, FN: 0\n"
     ]
    }
   ],
   "source": [
    "total_tp, total_fp, total_fn = 0, 0, 0\n",
    "\n",
    "for f_name in file_list:\n",
    "    im_bmp = np.array(Image.open(f'{f_name[:-4]}_n.png'))\n",
    "    im_mask = np.load(f_name[:-3]+'npy')\n",
    "\n",
    "    im_bmp = im_bmp / 255.0\n",
    "    slider = visualizer_slider(im_bmp, crop_size=512)\n",
    "    slider.make_tiles()\n",
    "    im_lst = torch.FloatTensor(np.array(slider.arr)).permute(0, 3, 1, 2)\n",
    "        \n",
    "    ################Segmentation model#####################\n",
    "    for i in range(im_lst.shape[0]):\n",
    "        data = im_lst[i:i + 1]\n",
    "        generated = model_seg(data)\n",
    "        generated = generated[:, 0:1, :, :]\n",
    "        \n",
    "        generated[generated >= .5] = 1\n",
    "        generated[generated < .5] = 0\n",
    "        \n",
    "        if device == 'cuda':\n",
    "            generated = generated.cpu()\n",
    "\n",
    "        slider.arr[i] = generated[0].permute(1, 2, 0).data.numpy()\n",
    "\n",
    "    slider.recover_mask()\n",
    "    ################Segmentation model#####################\n",
    "    \n",
    "    \n",
    "    #Extract segmentation patches for classification\n",
    "    seg_imgs, seg_im_labeled, prop_seg, prop_gt = extract_segmentation(im_bmp, slider.recvored_mak[:,:,0], im_mask, crop_size=120, j=10, n =7)    \n",
    "    \n",
    "    ################Classification model#####################\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    for i, (index, outs) in enumerate(prop_seg.iterrows()):\n",
    "        class_input = torch.FloatTensor(seg_imgs[i:i+1]).permute(0, 3, 1, 2)\n",
    "        class_out = model_class(class_input).round().item()\n",
    "\n",
    "        if class_out == 0:\n",
    "            seg_im_labeled[seg_im_labeled==index+1] = 0\n",
    "        elif class_out == 1:\n",
    "            counter+=1\n",
    "            flag = 1\n",
    "            for index_gr, p_gt in prop_gt.iterrows():\n",
    "                x1, y1, x2, y2, dist_x, dist_y, pred = validattion_func(prop_seg.iloc[i], p_gt)\n",
    "\n",
    "                if pred == 1:\n",
    "                    tp += 1\n",
    "                    flag = 0\n",
    "                    break\n",
    "            if flag == 1:\n",
    "                fp += 1\n",
    "\n",
    "    fn = len(prop_gt)-tp\n",
    "    print(f'image name: {f_name[-10:]},  TP: {tp}, FP: {fp}, FN: {fn}')\n",
    "    ################Classification model#####################\n",
    "    \n",
    "    ################Save output images#####################\n",
    "    seg_im_labeled[seg_im_labeled>0] = 1\n",
    "    Image.fromarray((seg_im_labeled * 255.0).astype(np.uint8)).save(f'outs/{f_name[-10:-3]}png', format=\"PNG\", quality=100, subsampling=0)\n",
    "    ################Save output images#####################\n",
    "\n",
    "    total_tp += tp\n",
    "    total_fp += fp\n",
    "    total_fn += fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ad79860c-2f88-460a-810e-096197527aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 188  |  FP: 29   |  FN: 36   |   F: 0.8526   |   R: 0.8392857142857143   |   P: 0.8663594470046083\n"
     ]
    }
   ],
   "source": [
    "R = total_tp / (total_tp + total_fn)\n",
    "P = total_tp / (total_tp + total_fp)\n",
    "F = 2 * ((R * P) / (R + P))\n",
    "print(f'TP: {total_tp}  |  FP: {total_fp}   |  FN: {total_fn}   |   F: {F:.4f}   |   R: {R}   |   P: {P}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65049bce-2e18-4ab7-8f7e-1e6bff10d101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
